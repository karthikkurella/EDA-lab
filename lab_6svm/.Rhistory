library(ggplot2)
library(ggpubr)
library(MASS)
library(caTools)
library(dplyr)
library(caret)
library(ggplot2)
str(mtcars)
training.samples <- mtcars$mpg %>%createDataPartition(p = 0.7, list = FALSE)
train <- mtcars[training.samples, ]
test <- mtcars[-training.samples, ]
model <- lm(mpg ~ disp + hp + drat + wt, mtcars)
summary(model)
pred1 = model %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model)/mean(mtcars$mpg)
model1<- lm(mpg ~ disp + drat + wt, mtcars)
summary(model1)
anova(model,model1)
model1<- lm(mpg ~ disp + drat , mtcars)
summary(model1)
anova(model,model1)
boxplot(mtcars$mpg,ylab="miles per galon",main="outlier detection")
OutVals = boxplot(mtcars$mpg, plot=FALSE)$out
OutVals
boxplot(mtcars$mpg,ylab="miles per galon",main="outlier detection")
pred1 = model %>% predict(test)
x=RMSE(pred1,test$dist)
x
library(tidyverse)
library(ggpubr)
library(MASS)
library(caTools)
library(dplyr)
library(caret)
str(cars)
scatter.smooth(x=cars$speed, y=cars$dist, main="Dist ~ Speed")
boxplot(cars$speed, main="Speed", sub=paste("Outlier rows: ", boxplot.stats(cars$speed)$out))  # box plot for 'speed'
boxplot(cars$dist, main="Distance", sub=paste("Outlier rows: ", boxplot.stats(cars$dist)$out))  # box plot for 'distance'
training.samples <- cars$dist %>%createDataPartition(p = 0.7, list = FALSE)
train <- cars[training.samples, ]
test <- cars[-training.samples, ]
nrow(test)
# y = mx+c
mean_x =sum(train$speed) / nrow(train)
mean_y=sum(train$dist) / nrow(train)
library(ggplot2)
ggplot(train)+geom_point(mapping = aes(x=speed,y=dist))
cov_xy =0
for(i in seq(length(train$speed))){
mean_diffx = train$speed[i] - mean_x
mean_diffy = train$dist[i] - mean_y
cov_xy= cov_xy+mean_diffx*mean_diffy
}
cov_xy
variance<-function(x){
var_xy = 0
for(i in seq(length(x)))
{
s = x[i] - mean_x
var_xy= var_xy+s*s
}
print(var_xy)
}
variance(train$speed)
m = cov_xy / variance(train$speed)
m
c = mean_y - m*(mean_x)
c
predictor<-function(x){
val = m*x+c
print(val)
}
predictor(10)
library(caret)
colnames(train)
model<- lm(dist~speed,data=train)
summary(model)
val=data.frame(speed=10)
val
pred = model %>% predict(val)
pred
pred1 = model %>% predict(test)
x=RMSE(pred1,test$dist)
x
x/mean(test$dist)
library(ggpubr)
library(MASS)
library(caTools)
library(dplyr)
library(caret)
library(ggplot2)
str(mtcars)
boxplot(mtcars$mpg,ylab="miles per galon",main="outlier detection")
training.samples <- mtcars$mpg %>%createDataPartition(p = 0.7, list = FALSE)
train <- mtcars[training.samples, ]
test <- mtcars[-training.samples, ]
model <- lm(mpg ~ disp + hp + drat + wt, mtcars)
summary(model)
model1<- lm(mpg ~ disp + drat , mtcars)
summary(model1)
pred1 = model %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model)/mean(mtcars$mpg)
x/mean(test$dist)
anova(model,model1)
numeric(x)/mean(test$dist)
x/mean(test$dist)
x/mean(test$mpg)
pred1 = model %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model)/mean(mtcars$mpg)
x/mean(test$mpg)
pred1 = model1 %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model1)/mean(mtcars$mpg)
x/mean(test$mpg)
library(ggpubr)
library(MASS)
library(caTools)
library(dplyr)
library(caret)
library(ggplot2)
str(mtcars)
boxplot(mtcars$mpg,ylab="miles per galon",main="outlier detection")
training.samples <- mtcars$mpg %>%createDataPartition(p = 0.7, list = FALSE)
train <- mtcars[training.samples, ]
test <- mtcars[-training.samples, ]
model <- lm(mpg ~ disp + hp + drat + wt, mtcars)
summary(model)
pred1 = model %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model)/mean(mtcars$mpg)
x/mean(test$mpg)
model1<- lm(mpg ~ disp + drat , mtcars)
summary(model1)
pred1 = model1 %>% predict(test)
x=RMSE(pred1,test$mpg)
x
sigma(model1)/mean(mtcars$mpg)
x/mean(test$mpg)
anova(model,model1)
library(astsa, quietly=TRUE, warn.conflicts=FALSE)
library(ggplot2)
library(knitr)
library(printr)
library(plyr)
library(dplyr)
library(tidyverse)
library(lubridate)
library(gridExtra)
library(reshape2)
library(TTR)
library(tseries)
library(forecast)
library(ggfortify)
library(caret)
#data()
data_master <- read.csv("E:/Sems/sem-8/essentials of data analytics/lab/GSPC.csv")
str(data_master)
sp_500 <- ts(data_master$High, start=c(1995, 1),end = c(2016,12), freq=12)
summary(sp_500)
sp_500
plot.ts(sp_500)
plot(sp_500,xlab="Date", ylab = "Passenger numbers (1000's)",main="Air Passenger numbers from 1949 to 1961")
boxplot(sp_500~cycle(sp_500),xlab="Date", ylab = "Closing price of the stock market" ,main ="Monthly closing price ")
decompose_data = decompose(sp_500,"multiplicative")
plot(decompose_data)
adf.test(sp_500)
autoplot(acf(sp_500,plot=FALSE))+ labs(title="Correlogram from 1995 to 2015")
sp500SMA<- SMA(sp_500, n=3)
plot.ts(sp500SMA)
sp_500
summary(sp_500)
cycle(sp_500)
#autoplot(sp_500) + geom_smooth(method="lm")+ labs(x ="Date", y ="Open", title="air")
class(sp_500)
sum(is.na(sp_500))
arimaAP <- auto.arima(sp_500SMA)
arimaAP <- auto.arima(sp_500)
summary(arimaAP)
forecastAP <- forecast(arimaAP, level = c(90), h = 12)
autoplot(forecastAP)
require(ISLR)
install.packages(ISLR)
install.packages("ISLR")
data()
data(ISLR)
names(Smarket)
data()
library(ISLR)
names(Smarket)
head(Smarket)
summary(Smarket)
library(corrplot)
correlations <- cor(Smarket[,1:8])
corrplot(correlations, method="circle")
library(caret)
training.samples <- Smarket$Direction %>%createDataPartition(p = 0.8, list = FALSE)
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
library(dplyr)
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- data[training.samples, ]
test <- data[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial)
summary(model_git)
summary(model_glm)
library(ISLR)
library(corrplot)
library(dplyr)
library(caret)
#data()
names(Smarket)
head(Smarket)
summary(Smarket)
correlations <- cor(Smarket[,1:8])
corrplot(correlations, method="circle")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- data[training.samples, ]
test <- data[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket[train], family = binomial)
library(ISLR)
library(corrplot)
library(dplyr)
library(caret)
#data()
names(Smarket)
head(Smarket)
summary(Smarket)
correlations <- cor(Smarket[,1:8])
corrplot(correlations, method="circle")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- data[training.samples, ]
test <- data[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket[train,], family = binomial)
library(ISLR)
library(corrplot)
library(dplyr)
library(caret)
#data()
names(Smarket)
head(Smarket)
summary(Smarket)
correlations <- cor(Smarket[,1:8])
corrplot(correlations, method="circle")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- data[training.samples, ]
test <- data[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial)
summary(model_glm)
glm.probs <- predict(model_glm,
newdata = Smarket[test,],
type = "response")
glm.probs <- predict(model_glm,
newdata =test,
type = "response")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- Smarket[training.samples, ]
test <- SmallDataNumeric[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = train, family = binomial)
summary(model_glm)
glm.probs <- predict(model_glm,
newdata =test,
type = "response")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- Smarket[training.samples, ]
test <- Smarket[-training.samples, ]
glm.probs <- predict(model_glm,
newdata =test,
type = "response")
table(glm.pred,Direction)
glm.pred <- ifelse(glm.probs > 0.5, "Up", "Down")
glm.pred
table(glm.pred,Direction)
attach(Smarket)
table(glm.pred,Direction)
table(glm.pred,Smarket$Direction)
sum(glm.pred)
nrow(glm.pred)
ncol(glm.pred)
table(train$Direction, predict > 0.5)
glm.probs <- predict(model_glm,
newdata =test,
type = "response")
table(train$Direction, predict > 0.5)
glm.probs <- predict(model_glm,
newdata =test,
type = "response")
table(train$Direction, glm.probs > 0.5)
glm.probs <- predict(model_glm,type = "response")
glm.probs <- predict(model_glm,type = "response")
table(train$Direction, glm.probs > 0.5)
library(ROCR)
library(ggplot2)
ggplot(train, aes(x=Rating, y=Recommended)) + geom_point() +
stat_smooth(method="glm", family="binomial", se=FALSE)
library(ggplot2)
ggplot(train, aes(x=Lag1, y=Direction)) + geom_point() +
stat_smooth(method="glm", family="binomial", se=FALSE)
library(ISLR)
library(corrplot)
library(dplyr)
library(caret)
#data()
names(Smarket)
head(Smarket)
summary(Smarket)
correlations <- cor(Smarket[,1:8])
corrplot(correlations, method="circle")
training.samples <- Smarket$Direction %>% createDataPartition(p = 0.8, list = FALSE)
train <- Smarket[training.samples, ]
test <- Smarket[-training.samples, ]
model_glm <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = train, family = binomial)
summary(model_glm)
glm.probs <- predict(model_glm,type = "response")
table(train$Direction, glm.probs > 0.5)
library(ggplot2)
ggplot(train, aes(x=Lag1, y=Direction)) + geom_point() +
stat_smooth(method="glm", family="binomial", se=FALSE)
library(ISLR)
library(corrplot)
library(dplyr)
library(caret)
install.packages("htmltools")
remove.packages("htmltools", lib="~/R/win-library/4.0")
install.packages("htmltools")
install.packages("htmltools")
tools:::.install_packges()
plot.ts(sp_500)+abline(reg=lm(sp_500~time(sp_500)),col="blue")
library(tree)
library(ggplot2) # Data visualization
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
install.packages("tree")
library(ggplot2) # Data visualization
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
getwd()
library(ggplot2) # Data visualization
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
data <- read.csv("bank.csv",sep = ";")
data <- read.csv("bank.csv",sep = ";")
idx <- sample(1:nrow(data),8)
data[idx,]
sapply(data, class)
data$age <- as.numeric(data$age)
data$balance <- as.numeric(data$balance)
data$day <- as.numeric(data$day)
data$duration <- as.numeric(data$duration)
data$campaign <- as.numeric(data$campaign)
data$pdays <- as.numeric(data$pdays)
data$previous <- as.numeric(data$previous)
size <- nrow(data) * 0.8
na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
education_testing <- education[-data_bank]
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predictions <- predict(data_training.rpart, data_bank, type = "class")
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predictions <- predict(data_training.rpart, data_bank, type = "class")
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predictions <- predict(data_training, data_bank, type = "class")
predict_unseen <-predict(data_training.rpart, data_test, type = 'class')
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
confusion.matrix <- prop.table(table(predictions, data_training$y))
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
confusion.matrix <- prop.table(table(predict_unseen, data_training$y))
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
confusion.matrix <- prop.table(table(predict_unseen, data_training$y))
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
table_mat <- table(data_test$y, predict_unseen)
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
table_mat <- table(data_testing$y, predict_unseen)
table_mat
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
table_mat <- table(data_testing$y, predict_unseen)
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
head(data)
glimpse(data)
size <- nrow(data) * 0.8
na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
education_testing <- education[-data_bank]
size <- nrow(data) * 0.8
na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
summary(data_training)
size <- nrow(data) * 0.8
na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
summary(data_training)
prop.table(table(data_training$y))
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
table_mat <- table(data_testing$y, predict_unseen)
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
size <- nrow(data) * 0.8
temo<-na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
summary(data_training)
prop.table(table(data_training$y))
library(ggplot2) # Data visualization
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
data <- read.csv("bank.csv",sep = ";")
idx <- sample(1:nrow(data),8)
sapply(data, class)
head(data)
glimpse(data)
data$age <- as.numeric(data$age)
data$balance <- as.numeric(data$balance)
data$day <- as.numeric(data$day)
data$duration <- as.numeric(data$duration)
data$campaign <- as.numeric(data$campaign)
data$pdays <- as.numeric(data$pdays)
data$previous <- as.numeric(data$previous)
size <- nrow(data) * 0.8
temo<-na.omit(data)
data_bank <- sample(1:nrow(data), size = size)
data_testing <- data[-data_bank,]	# Testing Data
data_training <- data[data_bank,]		# Training Data
summary(data_training)
prop.table(table(data_training$y))
data_training.rpart <- rpart(y ~ ., data = data_training)
fancyRpartPlot(data_training.rpart)
predict_unseen <-predict(data_training.rpart, data_testing, type = 'class')
table_mat <- table(data_testing$y, predict_unseen)
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
print(paste('Accuracy for test', accuracy_Test))
library(e1071)
load(file="ESL.mixture.rda")
ESL.mixture
setwd('E:\Sems\sem-8\essentials of data analytics\lab\lab_6svm')
setwd('E:\\Sems\\sem-8\\essentials of data analytics\\lab\\lab_6svm')
library(ggplot2)
library(e1071)
library(dplyr)
library(ggplot2)
test<-read.csv("test.csv")
train<- read.csv("train.csv")
getwd()
setwd('E:\\Sems\\sem-8\\essentials of data analytics\\lab\\lab_6svm\\')
getwd()
train<- read.csv("train.csv")
getwd()
setwd('E:\\Sems\\sem-8\\essentials of data analytics\\lab\\lab_6svm\\')
getwd()
setwd('E:\\Sems\\sem-8\\essentials of data analytics\\lab\\lab_6svm\\')
getwd()
train<- read.csv("train.csv")
getwd()
test<-read.csv("test.csv")
setwd('E:\\Sems\\sem-8\\essentials of data analytics\\lab\\lab_6svm\\')
train<- read.csv("train.csv")
test<-read.csv("test.csv")
glimpse(train)
sum(is.na(train))
sum(is.na(train$cabin))
sum(is.na(train$Embarked))
sum(is.na(train$Survived))
sum(is.na(train$Pclass))
sum(is.na(train$PassengerId))
